{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bcce045-e7e0-4891-b884-f6adf5915dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6496cb6a-30e2-4924-98bf-2986317513e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 22 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model for flowers\n",
    "model = load_model('flower_species_classifier.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf85772-703e-4f68-96c1-24016262b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "X_test = np.load('flower_species_classification/data_test.npy').T\n",
    "t_test = np.load('flower_species_classification/labels_test.npy')\n",
    "\n",
    "# Reshape and normalize \n",
    "X_test = X_test / 255.0  \n",
    "X_test = X_test.reshape(-1, 300, 300, 3)\n",
    "\n",
    "# One-hot encode test labels\n",
    "t_test_one_hot = to_categorical(t_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95609047-6854-4fa9-aff8-0389ab88a437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 248ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the class probabilities\n",
    "y_pred_p = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_p, axis=1)\n",
    "y_true = np.argmax(t_test_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d0e35a-3372-4911-9691-4761f13be23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Roses', 'Magnolias', 'Lilies', 'Sunflowers', 'Orchids', \n",
    "               'Marigold', 'Hibiscus', 'Firebush', 'Pentas', 'Bougainvillea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b242694-6590-4d07-9be9-8380674e7c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0867\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Roses       0.00      0.00      0.00        48\n",
      "    Magnolias       0.09      0.43      0.15        44\n",
      "       Lilies       0.00      0.00      0.00        46\n",
      "   Sunflowers       0.33      0.03      0.05        36\n",
      "      Orchids       0.12      0.07      0.09        45\n",
      "     Marigold       0.03      0.05      0.03        40\n",
      "     Hibiscus       0.04      0.05      0.04        43\n",
      "     Firebush       0.21      0.11      0.14        37\n",
      "       Pentas       0.00      0.00      0.00        32\n",
      "Bougainvillea       0.12      0.11      0.12        44\n",
      "\n",
      "     accuracy                           0.09       415\n",
      "    macro avg       0.10      0.08      0.06       415\n",
      " weighted avg       0.09      0.09      0.06       415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "test_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1561d9bb-acdb-4a0a-aa4f-8946ae09415c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conf_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the confusion matrix\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(conf_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m, xticklabels\u001b[38;5;241m=\u001b[39mclass_names, yticklabels\u001b[38;5;241m=\u001b[39mclass_names)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Label\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conf_matrix' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9584678-937c-4383-8bd6-b946bdb8973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizingtest samples with predictions\n",
    "n_samples = 3\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(num_samples):\n",
    "    idx = np.random.randint(0, len(X_test))\n",
    "    plt.subplot(1, num_samples, i + 1)\n",
    "    plt.imshow(X_test[idx])\n",
    "    plt.title(f\"True: {class_names[y_true[idx]]}\\nPred: {class_names[y_pred[idx]]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea494b6-78fc-4392-90f7-9d7c62e38cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = load_model('car_detection_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd65587-b69a-4616-a0aa-f55c27692e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window function\n",
    "def sliding__window(image, step_size, window_size):\n",
    "    for y in range(0, image.shape[0] - window_size[1], step_size):\n",
    "        for x in range(0, image.shape[1] - window_size[0], step_size):\n",
    "            yield (x, y, x + window_size[0], y + window_size[1]), image[y:y + window_size[1], x:x + window_size[0]]\n",
    "\n",
    "# Parameters for sliding window\n",
    "window_size = (100, 100)  # Width, Height\n",
    "step_size = 50  # Pixels to move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed5838f-8e4c-444e-af56-fb3a06c5098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "def plotdetected_boxes(image, predicted_boxes, title=\"Detected BoundingBoxes\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    for box in predicted_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        plt.plot([x1, x1, x2, x2, x1], [y1, y2, y2, y1, y1], color='blue', linestyle='--', linewidth=2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37393b18-2203-49fb-8de6-597eca656937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.image import resize\n",
    "\n",
    "# Process test images\n",
    "test_img_path = 'car_detection_dataset/testing_images/'\n",
    "test_img_files = os.listdir(test_img_path)\n",
    "detected_b_boxes = []\n",
    "\n",
    "for img_file in test_img_files:\n",
    "    img_path = test_img_path + img_file\n",
    "    image = np.array(Image.open(img_path))\n",
    "    org_image = image.copy()  # For visualization\n",
    "\n",
    "    # Normalize and reshape\n",
    "    image = image / 255.0\n",
    "    Nx, Ny, Nz = image.shape\n",
    "    detected_boxes = []\n",
    "\n",
    "    # Apply sliding window\n",
    "    for (x1, y1, x2, y2), patch in sliding_window(image, step_size, window_size):\n",
    "        # Skip patches smaller than the window size\n",
    "        if patch.shape[0] != window_size[1] or patch.shape[1] != window_size[0]:\n",
    "            continue\n",
    "        \n",
    "        # patch for prediction\n",
    "        patch_resized = resize(patch, (Nx, Ny))  # Resize to match training image size\n",
    "        patch_resized = np.expand_dims(patch_resized, axis=0)\n",
    "        \n",
    "        # Predict bounding box for the patch\n",
    "        pred_b_box = model.predict(patch_resized).round().astype(int)[0]\n",
    "        pred_b_box = [pred_b_box[0] + x1, pred_b_box[1] + y1, pred_b_box[2] + x1, pred_b_box[3] + y1]\n",
    "        \n",
    "        # Store predicted box\n",
    "        detected_boxes.append(pred_b_box)\n",
    "\n",
    "    # Visualize detected bounding boxes\n",
    "    plot_detected_boxes(org_image, detected_boxes, title=f\"Detected Bounding Boxes: {img_file}\")\n",
    "    detected_b_boxes.append(detected_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108eaae8-7ed4-4217-9f96-cd75174f3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detected bounding boxes\n",
    "np.save('detected_bounding_boxes.npy', detected_b_boxes)\n",
    "\n",
    "# Summary of detected boxes\n",
    "print(f\"Total test images processed: {len(test_img_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e3d33-57d1-45c9-8eb9-c3d82af5a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1_gt, y1_gt, x2_gt, y2_gt = box2\n",
    "    \n",
    "    # Intersection coordinates\n",
    "    xi1 = max(x1, x1_gt)\n",
    "    yi1 = max(y1, y1_gt)\n",
    "    xi2 = min(x2, x2_gt)\n",
    "    yi2 = min(y2, y2_gt)\n",
    "    \n",
    "    # Intersection and union areas\n",
    "    intersection = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2_gt - x1_gt) * (y2_gt - y1_gt)\n",
    "    union = box1_area + box2_area - intersection\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c469ffe-39d9-4720-a90f-47d7f8155909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recallf1(predictions, ground_truths, iou_threshold=0.5):\n",
    "    true_p, false_p, false_n = 0, 0, 0\n",
    "    \n",
    "    for pred, gt in zip(predictions, ground_truths):\n",
    "        iou = calculate_iou(pred, gt)\n",
    "        if iou >= iou_threshold:\n",
    "            true_p += 1\n",
    "        else:\n",
    "            false_p += 1\n",
    "            false_n += 1\n",
    "\n",
    "    precision = true_p / (true_p + false_p + 1e-6)\n",
    "    recall = true_p / (true_p + false_n + 1e-6)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f60fca-f55e-48bc-8a1b-a9856453c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_map(predictions, ground_truths, iou_thresholds=[0.5, 0.75]):\n",
    "    average_precisions = []\n",
    "    for threshold in iou_thresholds:\n",
    "        precision, recall, _ = precision_recall_f1(predictions, ground_truths, iou_threshold=threshold)\n",
    "        average_precisions.append((precision + recall) / 2)  \n",
    "    return np.mean(average_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc9ba5-a018-45cb-92ab-e2f1b63daeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elv_no_object(images, predictions):\n",
    "    correct_no_object = 0\n",
    "    total_no_object = 0\n",
    "    \n",
    "    for img, pred in zip(images, predictions):\n",
    "        if img_has_no_object(img) and pred == [0, 0, 0, 0]:  # No-object condition\n",
    "            correct_no_object += 1\n",
    "        total_no_object += 1\n",
    "    \n",
    "    return correct_no_object / total_no_object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b43c34-aef8-410b-99f9-ff08d5179703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision, recall, f1 = precision_recallf1( ground_truths, iou_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d72de-b4e2-4d57-b2cd-70e3966b3bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
